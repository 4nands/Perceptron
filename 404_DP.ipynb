{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSLCpy+pCA8LyJagN1Omdm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4nands/Perceptron/blob/main/404_DP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class GridWorld:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    self.map = np.array([\n",
        "        [0,0,0,1],\n",
        "        [0,0,0,-1],\n",
        "        [0,None,0,0],\n",
        "        [0,0,0,0]\n",
        "    ])\n",
        "    self.h = self.map.shape[0]\n",
        "    self.w = self.map.shape[1]\n",
        "    self.states = np.array([[i,j] for i in range(self.h) for j in range(self.w)])\n",
        "    self.action = np.array([[-1,0],[1,0],[0,-1],[0,1]])\n",
        "    self.direct = ['↑','↓','←','→']\n",
        "\n",
        "  def reward(self,s):\n",
        "    return self.map[*s]\n",
        "\n",
        "  def isGoal(self,s):\n",
        "    return all(s==[0,3])\n",
        "\n",
        "  def isWall(self,s):\n",
        "    return self.reward(s) == None\n",
        "\n",
        "  def move(self,s,a):\n",
        "\n",
        "    s_ = s + a\n",
        "    i,j = s_\n",
        "\n",
        "    if i < 0 or i >= self.h:\n",
        "      s_ = s\n",
        "    elif j < 0 or j >= self.w:\n",
        "      s_ = s\n",
        "    elif self.isWall(s_):\n",
        "      s_ = s\n",
        "\n",
        "    return s_\n",
        "\n",
        "  def get_map(self):\n",
        "\n",
        "    m = np.zeros_like(self.map)\n",
        "\n",
        "    for i in range(m.shape[0]):\n",
        "\n",
        "      for j in range(m.shape[1]):\n",
        "\n",
        "        n = self.map[i,j]\n",
        "\n",
        "        if n == 1:\n",
        "          c = '〇'\n",
        "        elif n == -1:\n",
        "          c = '×'\n",
        "        elif n == None:\n",
        "          c = '■'\n",
        "        else:\n",
        "          c = '□'\n",
        "\n",
        "        m[i,j] = c\n",
        "\n",
        "    return m\n",
        "\n",
        "def disp_map(map):\n",
        "  for r in map:\n",
        "    s = ''\n",
        "    for c in r:\n",
        "      s += c\n",
        "    print(s)\n",
        "\n",
        "class DPAgent:\n",
        "\n",
        "  def __init__(self,env):\n",
        "\n",
        "    self.env = env\n",
        "    self.V = np.zeros_like(self.env.map)\n",
        "    self.pi = np.zeros_like(self.env.map)\n",
        "\n",
        "  def Q(self,s,a):\n",
        "\n",
        "    s_ = env.move(s,a)\n",
        "\n",
        "    return self.env.reward(s_) + 0.9*self.V[*s_]\n",
        "\n",
        "  def value_iter(self):\n",
        "\n",
        "    delta = 1000\n",
        "\n",
        "    while delta > 1e-4:\n",
        "\n",
        "      V_ = self.V.copy()\n",
        "\n",
        "      for s in env.states:\n",
        "\n",
        "        values = []\n",
        "\n",
        "        if env.isGoal(s):\n",
        "          self.V[*s] = 0\n",
        "          continue\n",
        "\n",
        "        for a in env.action:\n",
        "\n",
        "          values += [self.Q(s,a)]\n",
        "\n",
        "        self.V[*s] = float(np.max(values))\n",
        "      delta = np.max(np.abs(self.V-V_))\n",
        "\n",
        "\n",
        "  def greedy_policy(self):\n",
        "\n",
        "    for s in env.states:\n",
        "\n",
        "      values = []\n",
        "\n",
        "      for a in env.action:\n",
        "\n",
        "          values += [self.Q(s,a)]\n",
        "\n",
        "      self.pi[*s] = int(np.argmax(values))\n",
        "\n",
        "  def policy(self,s):\n",
        "\n",
        "    return self.pi[*s]\n",
        "\n",
        "env = GridWorld()\n",
        "agent = DPAgent(env)\n",
        "agent.value_iter()\n",
        "agent.greedy_policy()\n",
        "\n",
        "\n",
        "map=env.get_map()\n",
        "\n",
        "ini = [3,0]\n",
        "s = np.array(ini)\n",
        "\n",
        "while not env.isGoal(s):\n",
        "  p = agent.policy(s)\n",
        "  d = env.direct[p]\n",
        "  map[*s] = d\n",
        "  a = env.action[p]\n",
        "  s = env.move(s,a)\n",
        "\n",
        "disp_map(map)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr_1Fyg7Y-n3",
        "outputId": "067c1dca-b71b-4b23-ad69-bab5e9e3296f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→→→〇\n",
            "↑□□×\n",
            "↑■□□\n",
            "↑□□□\n"
          ]
        }
      ]
    }
  ]
}