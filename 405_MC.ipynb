{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMufWFeTLWAUq+MrMjs89lr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4nands/Perceptron/blob/main/405_MC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv4Pddn9vVcj",
        "outputId": "b2cc3856-29ac-48fc-d230-0aa9cf8b2250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "□□→〇\n",
            "□■↑×\n",
            "→→↑□\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.action_space = [0, 1, 2, 3]\n",
        "\n",
        "        self.map = np.array(\n",
        "            [[0, 0, 0, 1.0],\n",
        "             [0, None, 0, -1.0],\n",
        "             [0, 0, 0, 0]]\n",
        "        )\n",
        "        self.goal_state = (0, 3)\n",
        "        self.wall_state = (1, 1)\n",
        "        self.start_state = (2, 0)\n",
        "        self.agent_state = self.start_state\n",
        "        self.h = self.map.shape[0]\n",
        "        self.w = self.map.shape[1]\n",
        "        self.states = [(i,j) for i in range(self.h) for j in range(self.w)]\n",
        "\n",
        "    def Goal(self,s):\n",
        "      return s == self.goal_state\n",
        "\n",
        "    def Wall(self,s):\n",
        "      return self.reward(s) == None\n",
        "\n",
        "    def Out(self,s):\n",
        "\n",
        "        i,j = s\n",
        "\n",
        "        if i < 0 or i >= self.h:\n",
        "          return True\n",
        "        elif j < 0 or j >= self.w:\n",
        "          return True\n",
        "        else:\n",
        "          return False\n",
        "\n",
        "    def next_state(self, s, a):\n",
        "        act = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
        "        m = act[a]\n",
        "        s_ = (s[0] + m[0], s[1] + m[1])\n",
        "\n",
        "        if self.Out(s_):\n",
        "            s_ = s\n",
        "        elif self.Wall(s_):\n",
        "            s_ = s\n",
        "\n",
        "        return s_\n",
        "\n",
        "    def reward(self, s):\n",
        "        return self.map[s]\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_state = self.start_state\n",
        "        return self.agent_state\n",
        "\n",
        "    def step(self, a):\n",
        "        s = self.agent_state\n",
        "        s_ = self.next_state(s, a)\n",
        "        r = self.reward(s_)\n",
        "        done = self.Goal(s_)\n",
        "\n",
        "        self.agent_state = s_\n",
        "        return s_, r, done\n",
        "\n",
        "    def get_map(self):\n",
        "\n",
        "        m = np.zeros_like(self.map)\n",
        "\n",
        "        for i in range(m.shape[0]):\n",
        "\n",
        "          for j in range(m.shape[1]):\n",
        "\n",
        "            n = self.map[i,j]\n",
        "\n",
        "            if n == 1:\n",
        "              c = '〇'\n",
        "            elif n == -1:\n",
        "              c = '×'\n",
        "            elif n == None:\n",
        "              c = '■'\n",
        "            else:\n",
        "              c = '□'\n",
        "\n",
        "            m[i,j] = c\n",
        "\n",
        "        return m\n",
        "\n",
        "def greedy_probs(Q, s, eps, size=4):\n",
        "    qs = [Q[(s, a)] for a in range(size)]\n",
        "    max_a = np.argmax(qs)\n",
        "\n",
        "    bp = eps / size\n",
        "    pdf = {a: bp for a in range(size)}\n",
        "    pdf[max_a] += (1 - eps)\n",
        "    return pdf\n",
        "\n",
        "\n",
        "class McAgent:\n",
        "    def __init__(self):\n",
        "\n",
        "        pdf = {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}\n",
        "        self.pi = defaultdict(lambda: pdf)\n",
        "        self.Q = defaultdict(lambda: 0)\n",
        "        self.memory = []\n",
        "\n",
        "    def get_action(self, state):\n",
        "        pdf = self.pi[state]\n",
        "        a = list(pdf.keys())\n",
        "        p = list(pdf.values())\n",
        "        return np.random.choice(a, p=p)\n",
        "\n",
        "    def add(self, s, a, r):\n",
        "        self.memory += [(s,a,r)]\n",
        "\n",
        "    def reset(self):\n",
        "        self.memory.clear()\n",
        "\n",
        "    def update(self):\n",
        "        G = 0\n",
        "        for s,a,r in reversed(self.memory):\n",
        "            G = 0.9 * G + r\n",
        "            k = (s, a)\n",
        "            self.Q[k] += (G - self.Q[k]) * 0.1\n",
        "            self.pi[s] = greedy_probs(self.Q, s, 0.1)\n",
        "\n",
        "def disp_map(map):\n",
        "  for r in map:\n",
        "    s = ''\n",
        "    for c in r:\n",
        "      s += c\n",
        "    print(s)\n",
        "\n",
        "env = GridWorld()\n",
        "agent = McAgent()\n",
        "\n",
        "for _ in range(100):\n",
        "\n",
        "    s = env.reset()\n",
        "    agent.reset()\n",
        "\n",
        "    while True:\n",
        "        a = agent.get_action(s)\n",
        "        s_, r, done = env.step(a)\n",
        "\n",
        "        agent.add(s, a, r)\n",
        "        if done:\n",
        "            agent.update()\n",
        "            break\n",
        "\n",
        "        s = s_\n",
        "s = (2,0)\n",
        "m = env.get_map()\n",
        "\n",
        "size = 4\n",
        "direct = {0:'↑',1:'↓',2:'←',3:'→'}\n",
        "while not env.Goal(s):\n",
        "  qs = [agent.Q[(s, a)] for a in range(size)]\n",
        "  a = np.argmax(qs)\n",
        "  d = direct[a]\n",
        "  i,j = s\n",
        "  m[i,j] = d\n",
        "  s = env.next_state(s,a)\n",
        "\n",
        "disp_map(m)"
      ]
    }
  ]
}